\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{SB}
\citation{JK}
\citation{Du_2019}
\citation{Du_2019}
\citation{Fahrmeir_2022}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Neural Networks}{1}{section.2}\protected@file@percent }
\newlabel{nn}{{2}{1}{Neural Networks}{section.2}{}}
\citation{LW}
\citation{LW}
\citation{bidaki2025}
\citation{LW}
\citation{bidaki2025,LW}
\citation{vandeVen2022}
\citation{vandeVen2022}
\citation{aljundi2019tfcl}
\citation{bidaki2025,LW}
\citation{bidaki2025}
\@writefile{toc}{\contentsline {section}{\numberline {3}Framework}{2}{section.3}\protected@file@percent }
\newlabel{framework}{{3}{2}{Framework}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Scenarios}{2}{subsection.3.1}\protected@file@percent }
\newlabel{scenarios}{{3.1}{2}{Scenarios}{subsection.3.1}{}}
\citation{vandeVen2022}
\citation{bidaki2025,LW}
\citation{bidaki2025,LW}
\citation{bidaki2025,LW}
\citation{FRENCH1999128,Mcclelland1995,MCCLOSKEY1989109,Ratcliff1990ConnectionistMO}
\citation{evron2022}
\citation{Shalev-Shwartz}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Stability-Plasticity Trade-off}{3}{subsection.3.2}\protected@file@percent }
\newlabel{cf}{{3.2}{3}{Stability-Plasticity Trade-off}{subsection.3.2}{}}
\citation{chaudhry2019,rebuffi2017icarlincrementalclassifierrepresentation,aljundi2019gradientbasedsampleselection}
\citation{lopezpaz2022gradientepisodicmemorycontinual,javed2019metalearningrepresentationscontinuallearning,mirzadeh2020understandingroletrainingregimes}
\citation{mallya2018piggybackadaptingsinglenetwork,ebrahimi2020adversarialcontinuallearning,fernando2017pathnetevolutionchannelsgradient}
\citation{LW}
\citation{díazrodríguez2018dontforgetforgettingnew}
\citation{díazrodríguez2018dontforgetforgettingnew}
\citation{LW}
\citation{lopezpaz2022gradientepisodicmemorycontinual}
\citation{díazrodríguez2018dontforgetforgettingnew}
\citation{LW}
\citation{LW}
\@writefile{toc}{\contentsline {section}{\numberline {4}Metrics}{4}{section.4}\protected@file@percent }
\newlabel{metrics}{{4}{4}{Metrics}{section.4}{}}
\citation{díazrodríguez2018dontforgetforgettingnew}
\citation{mirzadeh2020understandingroletrainingregimes}
\citation{mirzadeh2020understandingroletrainingregimes}
\citation{mirzadeh2020understandingroletrainingregimes}
\citation{evron2022,li2024fixeddesignanalysisregularizationbased}
\newlabel{2TA}{{13}{5}{Metrics}{equation.4.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Regularization}{5}{section.5}\protected@file@percent }
\newlabel{reg0}{{5}{5}{Regularization}{section.5}{}}
\citation{li2024fixeddesignanalysisregularizationbased}
\citation{li2024fixeddesignanalysisregularizationbased}
\citation{Fahrmeir_2022}
\citation{li2024fixeddesignanalysisregularizationbased,zhao2024statisticaltheoryregularizationbasedcontinual}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Regularization via Parameters}{6}{subsection.5.1}\protected@file@percent }
\newlabel{reg01}{{5.1}{6}{Regularization via Parameters}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Quadratic Penalties}{6}{subsubsection.5.1.1}\protected@file@percent }
\newlabel{reg011}{{5.1.1}{6}{Quadratic Penalties}{subsubsection.5.1.1}{}}
\citation{li2024fixeddesignanalysisregularizationbased}
\citation{zhao2024statisticaltheoryregularizationbasedcontinual}
\citation{zhao2024statisticaltheoryregularizationbasedcontinual}
\citation{zhao2024statisticaltheoryregularizationbasedcontinual}
\newlabel{oracle}{{18}{7}{Quadratic Penalties}{equation.5.18}{}}
\citation{zhao2024statisticaltheoryregularizationbasedcontinual}
\citation{zhao2024statisticaltheoryregularizationbasedcontinual}
\citation{JK}
\citation{JK}
\citation{zhao2024statisticaltheoryregularizationbasedcontinual,zenke2017continuallearningsynapticintelligence,Husz_r_2018,li2024fixeddesignanalysisregularizationbased,titsias2020functionalregularisationcontinuallearning,yin2021optimizationgeneralizationregularizationbasedcontinual,loo2020generalizedvariationalcontinuallearning,benzing2021unifyingregularisationmethodscontinual}
\citation{JK}
\citation{Fahrmeir_2022}
\citation{zenke2017continuallearningsynapticintelligence}
\citation{zenke2017continuallearningsynapticintelligence}
\newlabel{ewcBayes}{{20}{8}{Quadratic Penalties}{equation.5.20}{}}
\newlabel{EWC}{{21}{8}{Quadratic Penalties}{equation.5.21}{}}
\citation{aljundi2018memoryawaresynapseslearning}
\citation{aljundi2018memoryawaresynapseslearning}
\citation{benzing2021unifyingregularisationmethodscontinual}
\citation{yin2021optimizationgeneralizationregularizationbasedcontinual}
\citation{liu2018rotatenetworksbetterweight}
\citation{yin2021optimizationgeneralizationregularizationbasedcontinual}
\citation{jung2021continuallearningnodeimportancebased,yoon2018lifelonglearningdynamicallyexpandable}
\citation{Fahrmeir_2022}
\citation{yoon2018lifelonglearningdynamicallyexpandable}
\newlabel{SI}{{22}{9}{Quadratic Penalties}{equation.5.22}{}}
\newlabel{MAS}{{23}{9}{Quadratic Penalties}{equation.5.23}{}}
\newlabel{l2pen}{{24}{9}{Quadratic Penalties}{equation.5.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Sparse Penalties}{10}{subsubsection.5.1.2}\protected@file@percent }
\newlabel{reg012}{{5.1.2}{10}{Sparse Penalties}{subsubsection.5.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{10}{section.6}\protected@file@percent }
\newlabel{conclusion}{{6}{10}{Conclusion}{section.6}{}}
\citation{JK}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix}{V}{appendix.A}\protected@file@percent }
\newlabel{app}{{A}{V}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Expansion of eq. 2 in \cite  {JK} for $T$ samples \eqref  {ewcBayes}}{V}{subsection.A.1}\protected@file@percent }
\newlabel{ewcB}{{A.1}{V}{Expansion of eq. 2 in \cite {JK} for $T$ samples \eqref {ewcBayes}}{subsection.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Proof that CRR is biased}{V}{subsection.A.2}\protected@file@percent }
\newlabel{crr}{{A.2}{V}{Proof that CRR is biased}{subsection.A.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Electronic appendix}{VII}{appendix.B}\protected@file@percent }
\newlabel{el_app}{{B}{VII}{Electronic appendix}{appendix.B}{}}
\bibstyle{abbrvnat}
\bibdata{bibliography}
\bibcite{aljundi2018memoryawaresynapseslearning}{{1}{2018}{{Aljundi et~al.}}{{Aljundi, Babiloni, Elhoseiny, Rohrbach, and Tuytelaars}}}
\bibcite{aljundi2019tfcl}{{2}{2019{}}{{Aljundi et~al.}}{{Aljundi, Kelchtermans, and Tuytelaars}}}
\bibcite{aljundi2019gradientbasedsampleselection}{{3}{2019{}}{{Aljundi et~al.}}{{Aljundi, Lin, Goujaud, and Bengio}}}
\bibcite{SB}{{4}{2010}{{Bach and Maloof}}{{}}}
\bibcite{benzing2021unifyingregularisationmethodscontinual}{{5}{2021}{{Benzing}}{{}}}
\bibcite{bidaki2025}{{6}{2025}{{Bidaki et~al.}}{{Bidaki, Mohammadkhah, Rezaee, Hassani, Eskandari, Salahi, and Ghassemi}}}
\bibcite{chaudhry2019}{{7}{2019}{{Chaudhry et~al.}}{{Chaudhry, Rohrbach, Elhoseiny, Ajanthan, Dokania, Torr, and Ranzato}}}
\bibcite{Du_2019}{{8}{2019}{{Du and Swamy}}{{}}}
\bibcite{díazrodríguez2018dontforgetforgettingnew}{{9}{2018}{{Díaz-Rodríguez et~al.}}{{Díaz-Rodríguez, Lomonaco, Filliat, and Maltoni}}}
\bibcite{ebrahimi2020adversarialcontinuallearning}{{10}{2020}{{Ebrahimi et~al.}}{{Ebrahimi, Meier, Calandra, Darrell, and Rohrbach}}}
\bibcite{evron2022}{{11}{2022}{{Evron et~al.}}{{Evron, Moroshko, Ward, Srebro, and Soudry}}}
\bibcite{Fahrmeir_2022}{{12}{2022}{{Fahrmeir et~al.}}{{Fahrmeir, Kneib, Lang, and Marx}}}
\bibcite{fernando2017pathnetevolutionchannelsgradient}{{13}{2017}{{Fernando et~al.}}{{Fernando, Banarse, Blundell, Zwols, Ha, Rusu, Pritzel, and Wierstra}}}
\bibcite{FRENCH1999128}{{14}{1999}{{French}}{{}}}
\bibcite{Husz_r_2018}{{15}{2018}{{Huszár}}{{}}}
\bibcite{javed2019metalearningrepresentationscontinuallearning}{{16}{2019}{{Javed and White}}{{}}}
\bibcite{jung2021continuallearningnodeimportancebased}{{17}{2021}{{Jung et~al.}}{{Jung, Ahn, Cha, and Moon}}}
\bibcite{JK}{{18}{2017}{{Kirkpatrick et~al.}}{{Kirkpatrick, Pascanu, Rabinowitza, Veness, Guillaume~Desjardins, Milan, Quan, Ramalho, Agnieszk Grabska-Barwinska, Clopath, Kumaran, and Hadsell}}}
\bibcite{li2024fixeddesignanalysisregularizationbased}{{19}{2024}{{Li et~al.}}{{Li, Wu, and Braverman}}}
\bibcite{liu2018rotatenetworksbetterweight}{{20}{2018}{{Liu et~al.}}{{Liu, Masana, Herranz, de~Weijer, Lopez, and Bagdanov}}}
\bibcite{loo2020generalizedvariationalcontinuallearning}{{21}{2020}{{Loo et~al.}}{{Loo, Swaroop, and Turner}}}
\bibcite{lopezpaz2022gradientepisodicmemorycontinual}{{22}{2022}{{Lopez-Paz and Ranzato}}{{}}}
\bibcite{mallya2018piggybackadaptingsinglenetwork}{{23}{2018}{{Mallya et~al.}}{{Mallya, Davis, and Lazebnik}}}
\bibcite{Mcclelland1995}{{24}{1995}{{Mcclelland et~al.}}{{Mcclelland, Mcnaughton, and O'Reilly}}}
\bibcite{MCCLOSKEY1989109}{{25}{1989}{{McCloskey and Cohen}}{{}}}
\bibcite{mirzadeh2020understandingroletrainingregimes}{{26}{2020}{{Mirzadeh et~al.}}{{Mirzadeh, Farajtabar, Pascanu, and Ghasemzadeh}}}
\bibcite{Ratcliff1990ConnectionistMO}{{27}{1990}{{Ratcliff}}{{}}}
\bibcite{rebuffi2017icarlincrementalclassifierrepresentation}{{28}{2017}{{Rebuffi et~al.}}{{Rebuffi, Kolesnikov, Sperl, and Lampert}}}
\bibcite{Shalev-Shwartz}{{29}{2014}{{Shalev-Shwartz and Ben-David}}{{}}}
\bibcite{titsias2020functionalregularisationcontinuallearning}{{30}{2020}{{Titsias et~al.}}{{Titsias, Schwarz, de~G.~Matthews, Pascanu, and Teh}}}
\bibcite{vandeVen2022}{{31}{2022}{{van~de Ven et~al.}}{{van~de Ven, Tuytelaars, and Tolias}}}
\bibcite{LW}{{32}{2024}{{Wang et~al.}}{{Wang, Zhang, Su, Zhu, Fellow, and IEEE}}}
\bibcite{yin2021optimizationgeneralizationregularizationbasedcontinual}{{33}{2021}{{Yin et~al.}}{{Yin, Farajtabar, Li, Levine, and Mott}}}
\bibcite{yoon2018lifelonglearningdynamicallyexpandable}{{34}{2018}{{Yoon et~al.}}{{Yoon, Yang, Lee, and Hwang}}}
\bibcite{zenke2017continuallearningsynapticintelligence}{{35}{2017}{{Zenke et~al.}}{{Zenke, Poole, and Ganguli}}}
\bibcite{zhao2024statisticaltheoryregularizationbasedcontinual}{{36}{2024}{{Zhao et~al.}}{{Zhao, Wang, Huang, and Lin}}}
\gdef \@abspage@last{21}
