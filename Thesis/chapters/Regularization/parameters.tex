%%%%%%%%%%%%%%%%%%% Regularization via Parameters %%%%%%%%%%%%%%%%%%%
Assuming a CL problem with $T=2$ linear regression tasks. The task corresponding samples $D_1 = (X_1, y_1)$ and $D_2 = (X_2, y_2)$ do not necessarily come from the same population. The \textit{ordinary conitunal learning} \cite{evron2022,li2024fixeddesignanalysisregularizationbased} algorithm performs an ordinary least square minimization over the first sample set $D_1$ to estimate the parameters
\begin{equation}
	w_1 = (X_1^\top X_1)^{-1}X_1^\top y_1
\end{equation}. In the second training sequence, ordinary continual learning fits $D_2$ to the residuals of task one with respect to $X_2$. The new parameters $w_2$ are then:
\begin{equation}
	w_2 = w_1 + (X_2^\top X_2)^{-1}X_2^\top (y_2 - X_2w_1)
\end{equation}. In their analysis of ordinary continual learning \cite{li2024fixeddesignanalysisregularizationbased} show that it suffers from catastrophic forgetting when dealing with "dissimilar" tasks i.e.\cite{li2024fixeddesignanalysisregularizationbased} measure similarity via the following bound:
\begin{equation}
d_F \leq tr(H_1H_2^{-1})=o(n)
\end{equation}
where $d_F$ is the normed expected forgetting rate between the two tasks and $H_i, i\in\{1,2\}$ are the commutable covariance matrices $\frac{1}{n}X_i^\top X_i$.\\

%% Note: vielleicht passt dieser obere Teil besser in Chap. 3 (Framework)

Regularization of model weights, in a CL setting, penalizes based on the contribution to previous learning steps \cite{LW}. One way of measuring a weights influence is the Fisher information matrix. Kirkpatrick et al. \cite{JK} justify this approach through a probabilistic view of neural networks. They no longer want to find the parameters that best fit the data pattern but find the most probable model weights, depending on a given data sample. Using Bayes' Rule and the assumption of independent samples (e.g. CIL), they express the conditional probability $\mathbb{P}(w|\mathcal{D}^{(t)}), \mathcal{D}^{(t)} = \{D_1, ..., D_t\}$ of the weights as
\begin{equation}
	\log(\mathbb{P}(w|\mathcal{D}^{(t)})) = \log(\mathbb{P}(D_{t}|w)) + \log(\mathbb{P}(w|\mathcal{D}^{(t-1)})) - \log(\mathbb{P}(D_t))
\end{equation}
