%%%%%%%%%%%%%%%%%%% Regularization via Parameters %%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% L1 Norm %%%%%%%%%%%%%%%%%%%
The ridge like penalties provide control over a model's stability. Because their approximations become increasingly inaccurate with each new training step, they encourage smaller steps away from the current state of the model as training continues \cite{yin2021optimizationgeneralizationregularizationbasedcontinual}. All of the algorithms presented so far, imply that every parameters are, to some degree, useful across all tasks. \cite{jung2021continuallearningnodeimportancebased, yoon2018lifelonglearningdynamicallyexpandable} question this and suggest a Grouped-LASSO \cite{Fahrmeir_2022} penalty. The parameter groups are determined by the neurons they connect to or come from. This way the model can benefit from already established weights and simultaneously use free neurons to fit task specific parameters. In order to protect task individual neurons, \cite{yoon2018lifelonglearningdynamicallyexpandable} rely on multiple retraining of the same model to identify "empty" neurons. \\
